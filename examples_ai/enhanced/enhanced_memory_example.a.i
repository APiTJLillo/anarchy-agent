// enhanced_memory_example.a.i - Example demonstrating the enhanced memory system
// Shows how to use vector memory, hierarchical organization, and memory integration

// Import required modules
ŒπMemoryIntegration = require("../src/memory/enhanced/memory_integration");
ŒπLLMIntegration = require("../src/llm/llm_integration");

// Define string dictionary entries
üìù("example_init", "Initializing enhanced memory example...");
üìù("example_store", "Storing memory: {}");
üìù("example_retrieve", "Retrieving memory: {}");
üìù("example_search", "Searching memory: {}");
üìù("example_complete", "Example completed successfully!");

// Main example function
∆írun_example() {
    ‚åΩ(:example_init);
    
    // Initialize LLM integration for embeddings
    Œπllm = LLMIntegration();
    llm.initialize({
        model: "local/embedding-model",
        context_size: 4096
    });
    
    // Initialize memory system
    Œπmemory = MemoryIntegration();
    memory.initialize({
        storage_path: "./memory_storage",
        llm_integration: llm,
        embedding_dimensions: 384
    });
    
    // Create memory categories
    memory.create_category("research", {
        description: "Research notes and findings",
        metadata: { importance: 4 }
    });
    
    memory.create_category("projects", {
        description: "Project information and tasks",
        metadata: { importance: 5 }
    });
    
    // Create namespaces
    memory.create_namespace("ai_research", "research", {
        description: "Artificial Intelligence research"
    });
    
    memory.create_namespace("anarchy_project", "projects", {
        description: "Anarchy Inference project"
    });
    
    // Store memories with different content and metadata
    ‚åΩ(:example_store, "AI research note");
    Œπmemory1 = memory.store(
        "Vector embeddings are mathematical representations of words or concepts in a high-dimensional space. " +
        "They capture semantic relationships and allow for efficient similarity calculations.",
        {
            type: "research",
            importance: 4,
            tags: ["AI", "embeddings", "vectors"]
        },
        {
            namespace: "ai_research"
        }
    );
    
    ‚åΩ(:example_store, "Project implementation note");
    Œπmemory2 = memory.store(
        "The Anarchy Inference language uses emoji operators to represent common programming operations. " +
        "For example, ‚åΩ is used for output, ∆í for function definitions, and Œª for lambda expressions.",
        {
            type: "projects",
            importance: 5,
            tags: ["anarchy", "syntax", "emoji"]
        },
        {
            namespace: "anarchy_project"
        }
    );
    
    ‚åΩ(:example_store, "Connection between concepts");
    Œπmemory3 = memory.store(
        "Implementing vector embeddings in Anarchy Inference requires careful consideration of the emoji " +
        "operators to ensure the mathematical operations are clear and maintainable.",
        {
            type: "research",
            importance: 3,
            tags: ["AI", "anarchy", "implementation"]
        },
        {
            namespace: "ai_research",
            relationships: [
                {
                    target_id: memory1.id,
                    type: "references",
                    bidirectional: true
                },
                {
                    target_id: memory2.id,
                    type: "implements",
                    bidirectional: false
                }
            ]
        }
    );
    
    // Retrieve a memory by ID with related memories
    ‚åΩ(:example_retrieve, `Memory ${memory3.id}`);
    Œπretrieved_memory = memory.retrieve(memory3.id, {
        include_related: true
    });
    
    ‚åΩ(`Retrieved memory: ${retrieved_memory.content.substring(0, 50)}...`);
    ‚åΩ(`Memory path: ${retrieved_memory.path}`);
    ‚åΩ(`Related memories: ${retrieved_memory.related.length}`);
    
    // Perform semantic search
    ‚åΩ(:example_search, "vector embeddings in AI");
    Œπsemantic_results = memory.search("vector embeddings in AI", {
        search_type: "semantic",
        limit: 2
    });
    
    ‚åΩ(`Found ${semantic_results.length} memories related to "vector embeddings in AI"`);
    ‚àÄ(semantic_results, Œªresult, Œπindex {
        ‚åΩ(`Result ${index + 1}: ${result.memory.content.substring(0, 50)}...`);
        ‚åΩ(`Similarity: ${result.similarity.toFixed(4)}`);
    });
    
    // Search by metadata
    ‚åΩ(:example_search, "tags: anarchy");
    Œπmetadata_results = memory.search("", {
        search_type: "metadata",
        metadata: {
            tags: ["anarchy"]
        },
        limit: 2
    });
    
    ‚åΩ(`Found ${metadata_results.length} memories with tag "anarchy"`);
    ‚àÄ(metadata_results, Œªmemory, Œπindex {
        ‚åΩ(`Result ${index + 1}: ${memory.content.substring(0, 50)}...`);
    });
    
    // Search within a specific category
    ‚åΩ(:example_search, "implementation in research category");
    Œπcategory_results = memory.search("implementation", {
        search_type: "semantic",
        category: "research",
        limit: 2
    });
    
    ‚åΩ(`Found ${category_results.length} memories about "implementation" in research category`);
    ‚àÄ(category_results, Œªresult, Œπindex {
        ‚åΩ(`Result ${index + 1}: ${result.memory.content.substring(0, 50)}...`);
    });
    
    // Get memory statistics
    Œπstats = memory.get_stats();
    ‚åΩ(`Memory statistics: ${JSON.stringify(stats, null, 2)}`);
    
    // Get category hierarchy
    Œπhierarchy = memory.get_category_hierarchy();
    ‚åΩ(`Category hierarchy: ${JSON.stringify(hierarchy, null, 2)}`);
    
    ‚åΩ(:example_complete);
}

// Run the example
run_example();
