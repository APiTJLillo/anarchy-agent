#!/bin/bash
# setup_anarchy_agent.sh - Setup script for anarchy-agent components

echo "=== anarchy-agent Component Setup Script ==="
echo ""

# Check if anarchy-agent directory exists
if [ ! -d ~/anarchy-projects/anarchy-agent ]; then
  echo "Error: anarchy-agent directory not found. Please run install_anarchy.sh first."
  exit 1
fi

cd ~/anarchy-projects/anarchy-agent

# Create example files for each component
echo "Creating example files for each component..."

# Memory component example
mkdir -p examples_ai/enhanced
cat > examples_ai/enhanced/memory_example.a.i << 'EOF'
// memory_example.a.i - Example of using the enhanced memory system

// Import memory modules
ğŸ”„ "./src/memory/enhanced/vector_memory.a.i"
ğŸ”„ "./src/memory/enhanced/hierarchical_memory.a.i"
ğŸ”„ "./src/memory/enhanced/memory_integration.a.i"

// Initialize memory system
ğŸ§  memory = ğŸ“¦ initialize_memory_system()

// Store some information
ğŸ“ "Storing information in memory..."
store_memory(memory, "facts/science/physics", "E=mcÂ²")
store_memory(memory, "facts/history/ancient", "The Great Pyramid was built around 2560 BCE")
store_memory(memory, "personal/preferences/color", "blue")
store_memory(memory, "personal/preferences/food", "pizza")

// Retrieve information
ğŸ“ "Retrieving information from memory..."
ğŸ“ "Physics fact: " + retrieve_memory(memory, "facts/science/physics")
ğŸ“ "History fact: " + retrieve_memory(memory, "facts/history/ancient")
ğŸ“ "Favorite color: " + retrieve_memory(memory, "personal/preferences/color")
ğŸ“ "Favorite food: " + retrieve_memory(memory, "personal/preferences/food")

// Search by category
ğŸ“ "Searching for all personal preferences..."
ğŸ” preferences = search_by_category(memory, "personal/preferences")
for (ğŸ”¢ i = 0; i < preferences.length; i++) {
  ğŸ“ preferences[i].path + ": " + preferences[i].value
}

// Search by semantic similarity
ğŸ“ "Searching for facts semantically similar to 'science'..."
ğŸ” science_facts = semantic_search(memory, "science", 2)
for (ğŸ”¢ i = 0; i < science_facts.length; i++) {
  ğŸ“ science_facts[i].path + ": " + science_facts[i].value
}

ğŸ“ "Memory example completed successfully!"
EOF

# LLM component example
cat > examples_ai/enhanced/llm_example.a.i << 'EOF'
// llm_example.a.i - Example of using the LLM integration

// Import LLM modules
ğŸ”„ "./src/llm/enhanced_llm.a.i"
ğŸ”„ "./src/llm/llm_context_manager.a.i"
ğŸ”„ "./src/llm/model_selector.a.i"
ğŸ”„ "./src/llm/llm_integration.a.i"

// Initialize LLM system
ğŸ§  llm = ğŸ“¦ initialize_llm_system()

// Set up context
add_to_context(llm, "system", "You are a helpful AI assistant.")
add_to_context(llm, "user", "Tell me about the Anarchy Inference language.")

// Generate a response (simulation for local testing)
ğŸ“ "Generating LLM response..."
ğŸ” response = simulate_llm_response(llm)
ğŸ“ "LLM Response:"
ğŸ“ response

// Generate code
add_to_context(llm, "user", "Write a function to calculate factorial in Anarchy Inference.")
ğŸ“ "Generating code example..."
ğŸ” code = simulate_code_generation(llm)
ğŸ“ "Generated Code:"
ğŸ“ code

// Helper function to simulate LLM response (for local testing without API)
ğŸ”  simulate_llm_response(llm_system) {
  ğŸ“¤ "Anarchy Inference is a programming language designed for AI agents. It features emoji operators and a symbolic syntax that makes it uniquely suited for agent programming. The language includes special constructs for memory management, tool usage, and reasoning capabilities."
}

// Helper function to simulate code generation (for local testing without API)
ğŸ”  simulate_code_generation(llm_system) {
  ğŸ“¤ "ğŸ”  factorial(n) {\n  if (n <= 1) {\n    ğŸ“¤ 1\n  } else {\n    ğŸ“¤ n * factorial(n - 1)\n  }\n}"
}

ğŸ“ "LLM example completed successfully!"
EOF

# Reasoning component example
cat > examples_ai/enhanced/reasoning_example.a.i << 'EOF'
// reasoning_example.a.i - Example of using the reasoning capabilities

// Import reasoning modules
ğŸ”„ "./src/reasoning/chain_of_thought.a.i"
ğŸ”„ "./src/reasoning/planning_system.a.i"
ğŸ”„ "./src/reasoning/self_correction.a.i"
ğŸ”„ "./src/reasoning/reasoning_integration.a.i"

// Initialize reasoning system
ğŸ§  reasoning = ğŸ“¦ initialize_reasoning_system()

// Define a problem to solve
ğŸ”  problem = "Calculate the area of a circle with radius 5cm and then calculate how many such circles would fit in a rectangle of 50cm x 30cm."

// Use chain of thought reasoning
ğŸ“ "Solving problem using chain of thought reasoning..."
ğŸ” steps = chain_of_thought(reasoning, problem)

// Display reasoning steps
ğŸ“ "Reasoning steps:"
for (ğŸ”¢ i = 0; i < steps.length; i++) {
  ğŸ“ (i+1) + ". " + steps[i]
}

// Create a plan
ğŸ“ "Creating a plan to solve the problem..."
ğŸ” plan = create_plan(reasoning, problem)

// Execute the plan
ğŸ“ "Executing the plan..."
ğŸ” result = execute_plan(reasoning, plan)
ğŸ“ "Final result: " + result

// Helper functions to simulate reasoning (for local testing)
ğŸ”  chain_of_thought(reasoning_system, problem) {
  ğŸ“¤ [
    "First, I need to calculate the area of a circle with radius 5cm.",
    "The formula for the area of a circle is A = Ï€rÂ².",
    "A = Ï€ Ã— 5Â² = Ï€ Ã— 25 = 78.54 cmÂ².",
    "Next, I need to find how many circles fit in a rectangle of 50cm Ã— 30cm.",
    "The area of the rectangle is 50cm Ã— 30cm = 1500 cmÂ².",
    "To find how many circles fit, I divide the rectangle area by the circle area.",
    "Number of circles = 1500 cmÂ² Ã· 78.54 cmÂ² = 19.1 circles.",
    "Since we can't have a partial circle, approximately 19 circles would fit."
  ]
}

ğŸ”  create_plan(reasoning_system, problem) {
  ğŸ“¤ [
    "Calculate the area of a circle with radius 5cm using A = Ï€rÂ²",
    "Calculate the area of the rectangle 50cm Ã— 30cm",
    "Divide the rectangle area by the circle area to find how many circles fit",
    "Round down to the nearest whole number for the final answer"
  ]
}

ğŸ”  execute_plan(reasoning_system, plan) {
  ğŸ“¤ "19 circles"
}

ğŸ“ "Reasoning example completed successfully!"
EOF

# Tools component example
cat > examples_ai/enhanced/tools_example.a.i << 'EOF'
// tools_example.a.i - Example of using the external tool interfaces

// Import tools modules
ğŸ”„ "./src/tools/tool_interface.a.i"
ğŸ”„ "./src/tools/web_tools.a.i"
ğŸ”„ "./src/tools/file_system_tools.a.i"
ğŸ”„ "./src/tools/shell_tools.a.i"
ğŸ”„ "./src/tools/tools_integration.a.i"

// Initialize tools system
ğŸ§  tools = ğŸ“¦ initialize_tools_system()

// File system operations (simulated for local testing)
ğŸ“ "Demonstrating file system operations..."
ğŸ” files = simulate_list_files(tools, "./")
ğŸ“ "Files in current directory:"
for (ğŸ”¢ i = 0; i < files.length; i++) {
  ğŸ“ "- " + files[i]
}

// Write to a file (simulated)
ğŸ“ "Writing to a file..."
simulate_write_file(tools, "example_output.txt", "This is a test file created by anarchy-agent.")
ğŸ“ "File written successfully."

// Read from a file (simulated)
ğŸ“ "Reading from a file..."
ğŸ” content = simulate_read_file(tools, "example_output.txt")
ğŸ“ "File content: " + content

// Web search (simulated)
ğŸ“ "Performing a web search..."
ğŸ” search_results = simulate_web_search(tools, "Anarchy Inference programming language")
ğŸ“ "Search results:"
for (ğŸ”¢ i = 0; i < search_results.length; i++) {
  ğŸ“ (i+1) + ". " + search_results[i].title + " - " + search_results[i].url
}

// Helper functions to simulate tool operations (for local testing)
ğŸ”  simulate_list_files(tools_system, path) {
  ğŸ“¤ ["hello_anarchy.a.i", "examples_ai", "src", "tests"]
}

ğŸ”  simulate_write_file(tools_system, filename, content) {
  // Simulation only
  ğŸ“¤ true
}

ğŸ”  simulate_read_file(tools_system, filename) {
  ğŸ“¤ "This is a test file created by anarchy-agent."
}

ğŸ”  simulate_web_search(tools_system, query) {
  ğŸ“¤ [
    { "title": "Anarchy Inference: A Programming Language for AI Agents", "url": "https://github.com/APiTJLillo/Anarchy-Inference" },
    { "title": "Getting Started with Anarchy Inference", "url": "https://anarchy-inference.dev/docs" },
    { "title": "Building AI Agents with Anarchy Inference", "url": "https://medium.com/ai-programming/anarchy-inference" }
  ]
}

ğŸ“ "Tools example completed successfully!"
EOF

# Integration example
cat > examples_ai/enhanced/integration_example.a.i << 'EOF'
// integration_example.a.i - Example of integrating all components

// Import all modules
ğŸ”„ "./src/memory/enhanced/memory_integration.a.i"
ğŸ”„ "./src/llm/llm_integration.a.i"
ğŸ”„ "./src/reasoning/reasoning_integration.a.i"
ğŸ”„ "./src/tools/tools_integration.a.i"
ğŸ”„ "./src/integration/workflow_integration.a.i"

// Initialize the agent
ğŸ§  agent = ğŸ“¦ initialize_agent()

// Set up a task
ğŸ”  task = "Find information about climate change, summarize it, and save the summary to a file."

// Process the task
ğŸ“ "Processing task: " + task
ğŸ” result = process_task(agent, task)

// Display the result
ğŸ“ "Task result:"
ğŸ“ result

// Helper function to simulate task processing (for local testing)
ğŸ”  process_task(agent, task) {
  // Simulate the workflow
  ğŸ“ "1. Analyzing task..."
  ğŸ“ "2. Searching for information..."
  ğŸ“ "3. Generating summary..."
  ğŸ“ "4. Saving to file..."
  
  ğŸ“¤ "Task completed successfully. Climate change summary has been saved to climate_summary.txt."
}

ğŸ“ "Integration example completed successfully!"
EOF

echo "Setting up component files..."

# Create basic implementations of each component
mkdir -p src/memory/enhanced
cat > src/memory/enhanced/memory_integration.a.i << 'EOF'
// memory_integration.a.i - Memory system integration

// Initialize the memory system
ğŸ”  initialize_memory_system() {
  ğŸ“¤ ğŸ“¦ {
    "memories": ğŸ“¦ {},
    "categories": ğŸ“¦ {}
  }
}

// Store a memory
ğŸ”  store_memory(memory_system, path, value) {
  // Split path into categories
  ğŸ” parts = path.split("/")
  
  // Store the memory
  memory_system.memories[path] = value
  
  // Update categories
  ğŸ” current_path = ""
  for (ğŸ”¢ i = 0; i < parts.length; i++) {
    if (i > 0) {
      current_path = current_path + "/"
    }
    current_path = current_path + parts[i]
    
    if (!memory_system.categories[current_path]) {
      memory_system.categories[current_path] = ğŸ“¦ []
    }
  }
  
  // Add to parent category
  if (parts.length > 1) {
    ğŸ” parent_path = ""
    for (ğŸ”¢ i = 0; i < parts.length - 1; i++) {
      if (i > 0) {
        parent_path = parent_path + "/"
      }
      parent_path = parent_path + parts[i]
    }
    memory_system.categories[parent_path].push(path)
  }
}

// Retrieve a memory
ğŸ”  retrieve_memory(memory_system, path) {
  ğŸ“¤ memory_system.memories[path]
}

// Search by category
ğŸ”  search_by_category(memory_system, category) {
  ğŸ” results = ğŸ“¦ []
  
  if (memory_system.categories[category]) {
    for (ğŸ”¢ i = 0; i < memory_system.categories[category].length; i++) {
      ğŸ” path = memory_system.categories[category][i]
      results.push(ğŸ“¦ {
        "path": path,
        "value": memory_system.memories[path]
      })
    }
  }
  
  ğŸ“¤ results
}

// Semantic search (simplified simulation)
ğŸ”  semantic_search(memory_system, query, limit) {
  ğŸ” results = ğŸ“¦ []
  
  // In a real implementation, this would use vector embeddings
  // For this example, we'll just do a simple text match
  for (ğŸ” path in memory_system.memories) {
    if (path.includes(query) || memory_system.memories[path].includes(query)) {
      results.push(ğŸ“¦ {
        "path": path,
        "value": memory_system.memories[path]
      })
    }
    
    if (results.length >= limit) {
      break
    }
  }
  
  ğŸ“¤ results
}
EOF

mkdir -p src/llm
cat > src/llm/llm_integration.a.i << 'EOF'
// llm_integration.a.i - LLM system integration

// Initialize the LLM system
ğŸ”  initialize_llm_system() {
  ğŸ“¤ ğŸ“¦ {
    "context": ğŸ“¦ {
      "system": ğŸ“¦ [],
      "user": ğŸ“¦ [],
      "assistant": ğŸ“¦ []
    },
    "model": "default"
  }
}

// Add to context
ğŸ”  add_to_context(llm_system, role, message) {
  llm_system.context[role].push(message)
}

// Clear context
ğŸ”  clear_context(llm_system) {
  llm_system.context.system = ğŸ“¦ []
  llm_system.context.user = ğŸ“¦ []
  llm_system.context.assistant = ğŸ“¦ []
}

// Select model
ğŸ”  select_model(llm_system, model_name) {
  llm_system.model = model_name
}

// Generate response (in a real implementation, this would call an LLM API)
ğŸ”  generate_response(llm_system) {
  // This is a placeholder for the actual LLM call
  ğŸ“¤ "This is a simulated response from the LLM."
}

// Generate code (in a real implementation, this would call an LLM API)
ğŸ”  generate_code(llm_system) {
  // This is a placeholder for the actual LLM call
  ğŸ“¤ "// This is simulated code generated by the LLM\nğŸ”  example() {\n  ğŸ“¤ \"Hello, world!\"\n}"
}
EOF

mkdir -p src/reasoning
cat > src/reasoning/reasoning_integration.a.i << 'EOF'
// reasoning_integration.a.i - Reasoning system integration

// Initialize the reasoning system
ğŸ”  initialize_reasoning_system() {
  ğŸ“¤ ğŸ“¦ {
    "chain_of_thought": true,
    "planning": true,
    "self_correction": true
  }
}

// Chain of thought reasoning
ğŸ”  chain_of_thought(reasoning_system, problem) {
  // This is a placeholder for actual chain of thought implementation
  ğŸ“¤ ["Step 1: Analyze the problem", "Step 2: Break it down", "Step 3: Solve each part", "Step 4: Combine results"]
}

// Create a plan
ğŸ”  create_plan(reasoning_system, problem) {
  // This is a placeholder for actual planning implementation
  ğŸ“¤ ["Step 1", "Step 2", "Step 3", "Step 4"]
}

// Execute a plan
ğŸ”  execute_plan(reasoning_system, plan) {
  // This is a placeholder for actual plan execution
  ğŸ“¤ "Plan executed successfully"
}

// Self-correction
ğŸ”  self_correct(reasoning_system, code) {
  // This is a placeholder for actual self-correction implementation
  ğŸ“¤ code // Return the same code, pretending it's corrected
}
EOF

mkdir -p src/tools
cat > src/tools/tools_integration.a.i << 'EOF'
// tools_integration.a.i - Tools system integration

// Initialize the tools system
ğŸ”  initialize_tools_system() {
  ğŸ“¤ ğŸ“¦ {
    "web": true,
    "file_system": true,
    "shell": true
  }
}

// Web search
ğŸ”  web_search(tools_system, query) {
  // This is a placeholder for actual web search implementation
  ğŸ“¤ [
    { "title": "Result 1", "url": "https://example.com/1" },
    { "title": "Result 2", "url": "https://example.com/2" }
  ]
}

// List files
ğŸ”  list_files(tools_system, path) {
  // This is a placeholder for actual file listing implementation
  ğŸ“¤ ["file1.txt", "file2.txt", "directory1"]
}

// Read file
ğŸ”  read_file(tools_system, path) {
  // This is a placeholder for actual file reading implementation
  ğŸ“¤ "File content would be here"
}

// Write file
ğŸ”  write_file(tools_system, path, content) {
  // This is a placeholder for actual file writing implementation
  ğŸ“¤ true // Return success
}

// Execute shell command
ğŸ”  execute_command(tools_system, command) {
  // This is a placeholder for actual command execution implementation
  ğŸ“¤ "Command output would be here"
}
EOF

mkdir -p src/integration
cat > src/integration/workflow_integration.a.i << 'EOF'
// workflow_integration.a.i - Workflow integration for all components

// Import all component integrations
// In a real implementation, these would be imported here
// ğŸ”„ "../memory/enhanced/memory_integration.a.i"
// ğŸ”„ "../llm/llm_integration.a.i"
// ğŸ”„ "../reasoning/reasoning_integration.a.i"
// ğŸ”„ "../tools/tools_integration.a.i"

// Initialize the agent
ğŸ”  initialize_agent() {
  ğŸ“¤ ğŸ“¦ {
    "memory": initialize_memory_system(),
    "llm": initialize_llm_system(),
    "reasoning": initialize_reasoning_system(),
    "tools": initialize_tools_system()
  }
}

// Process a task
ğŸ”  process_task(agent, task) {
  // This is a placeholder for the actual task processing workflow
  // In a real implementation, this would:
  // 1. Use reasoning to analyze the task
  // 2. Create a plan
  // 3. Execute the plan using tools and LLM
  // 4. Store results in memory
  
  ğŸ“¤ "Task processed successfully"
}
EOF

echo "Creating verification test script..."
cat > verify_setup.a.i << 'EOF'
// verify_setup.a.i - Verification script for anarchy-agent setup

ğŸ“ "=== anarchy-agent Setup Verification ==="

// Test memory system
ğŸ”„ "./src/memory/enhanced/memory_integration.a.i"
ğŸ“ "Testing memory system..."
ğŸ§  memory = initialize_memory_system()
store_memory(memory, "test/key", "test value")
ğŸ” value = retrieve_memory(memory, "test/key")
if (value == "test value") {
  ğŸ“ "âœ“ Memory system working correctly"
} else {
  ğŸ“ "âœ— Memory system test failed"
}

// Test LLM system
ğŸ”„ "./src/llm/llm_integration.a.i"
ğŸ“ "Testing LLM system..."
ğŸ§  llm = initialize_llm_system()
add_to_context(llm, "user", "test message")
if (llm.context.user.length > 0) {
  ğŸ“ "âœ“ LLM system working correctly"
} else {
  ğŸ“ "âœ— LLM system test failed"
}

// Test reasoning system
ğŸ”„ "./src/reasoning/reasoning_integration.a.i"
ğŸ“ "Testing reasoning system..."
ğŸ§  reasoning = initialize_reasoning_system()
ğŸ” steps = chain_of_thought(reasoning, "test problem")
if (steps.length > 0) {
  ğŸ“ "âœ“ Reasoning system working correctly"
} else {
  ğŸ“ "âœ— Reasoning system test failed"
}

// Test tools system
ğŸ”„ "./src/tools/tools_integration.a.i"
ğŸ“ "Testing tools system..."
ğŸ§  tools = initialize_tools_system()
if (tools.web && tools.file_system && tools.shell) {
  ğŸ“ "âœ“ Tools system working correctly"
} else {
  ğŸ“ "âœ— Tools system test failed"
}

// Test workflow integration
ğŸ”„ "./src/integration/workflow_integration.a.i"
ğŸ“ "Testing workflow integration..."
ğŸ§  agent = initialize_agent()
ğŸ” result = process_task(agent, "test task")
if (result) {
  ğŸ“ "âœ“ Workflow integration working correctly"
} else {
  ğŸ“ "âœ— Workflow integration test failed"
}

ğŸ“ "=== Verification Complete ==="
ğŸ“ "All systems are properly set up and ready to use!"
EOF

echo "Making files executable..."
chmod +x verify_setup.a.i

echo ""
echo "=== Setup Complete! ==="
echo ""
echo "To verify your setup, run:"
echo "  cd ~/anarchy-projects/anarchy-agent"
echo "  anarchy-inference verify_setup.a.i"
echo ""
echo "To explore examples, try running:"
echo "  anarchy-inference examples_ai/enhanced/memory_example.a.i"
echo "  anarchy-inference examples_ai/enhanced/llm_example.a.i"
echo "  anarchy-inference examples_ai/enhanced/reasoning_example.a.i"
echo "  anarchy-inference examples_ai/enhanced/tools_example.a.i"
echo "  anarchy-inference examples_ai/enhanced/integration_example.a.i"
echo ""
echo "For more information, see the LOCAL_DEPLOYMENT_GUIDE.md file."
