#!/bin/bash
# test_anarchy_agent.sh - Test script for verifying anarchy-agent functionality

echo "=== anarchy-agent Functionality Test Script ==="
echo ""

# Check if anarchy-agent directory exists
if [ ! -d ~/anarchy-projects/anarchy-agent ]; then
  echo "Error: anarchy-agent directory not found. Please run install_anarchy.sh first."
  exit 1
fi

cd ~/anarchy-projects/anarchy-agent

# Create a comprehensive test file
echo "Creating comprehensive test file..."
cat > comprehensive_test.a.i << 'EOF'
// comprehensive_test.a.i - Complete test of anarchy-agent functionality

ğŸ“ "=== anarchy-agent Comprehensive Test ==="
ğŸ“ "Starting test at: " + new Date().toString()

// Import all core modules
ğŸ”„ "./src/memory/enhanced/memory_integration.a.i"
ğŸ”„ "./src/llm/llm_integration.a.i"
ğŸ”„ "./src/reasoning/reasoning_integration.a.i"
ğŸ”„ "./src/tools/tools_integration.a.i"
ğŸ”„ "./src/integration/workflow_integration.a.i"

// Test 1: Memory System
ğŸ“ "\n=== Test 1: Memory System ==="
ğŸ§  memory = initialize_memory_system()

ğŸ“ "Testing memory storage and retrieval..."
store_memory(memory, "test/string", "This is a string value")
store_memory(memory, "test/number", 42)
store_memory(memory, "test/boolean", true)
store_memory(memory, "test/nested/value", "Nested value")

ğŸ” string_value = retrieve_memory(memory, "test/string")
ğŸ” number_value = retrieve_memory(memory, "test/number")
ğŸ” boolean_value = retrieve_memory(memory, "test/boolean")
ğŸ” nested_value = retrieve_memory(memory, "test/nested/value")

ğŸ“ "Retrieved values:"
ğŸ“ "- String: " + string_value
ğŸ“ "- Number: " + number_value
ğŸ“ "- Boolean: " + boolean_value
ğŸ“ "- Nested: " + nested_value

ğŸ“ "Testing category search..."
ğŸ” test_category = search_by_category(memory, "test")
ğŸ“ "Found " + test_category.length + " items in 'test' category:"
for (ğŸ”¢ i = 0; i < test_category.length; i++) {
  ğŸ“ "- " + test_category[i].path + ": " + test_category[i].value
}

ğŸ“ "Testing semantic search..."
ğŸ” semantic_results = semantic_search(memory, "value", 2)
ğŸ“ "Found " + semantic_results.length + " items matching 'value':"
for (ğŸ”¢ i = 0; i < semantic_results.length; i++) {
  ğŸ“ "- " + semantic_results[i].path + ": " + semantic_results[i].value
}

ğŸ“ "Memory system test completed âœ“"

// Test 2: LLM System
ğŸ“ "\n=== Test 2: LLM System ==="
ğŸ§  llm = initialize_llm_system()

ğŸ“ "Testing context management..."
add_to_context(llm, "system", "You are a helpful assistant.")
add_to_context(llm, "user", "What is Anarchy Inference?")
add_to_context(llm, "assistant", "Anarchy Inference is a programming language designed for AI agents.")
add_to_context(llm, "user", "How do I use it?")

ğŸ“ "Context contains " + llm.context.system.length + " system messages"
ğŸ“ "Context contains " + llm.context.user.length + " user messages"
ğŸ“ "Context contains " + llm.context.assistant.length + " assistant messages"

ğŸ“ "Testing model selection..."
select_model(llm, "gpt-4")
ğŸ“ "Selected model: " + llm.model

ğŸ“ "Testing response generation..."
ğŸ” response = generate_response(llm)
ğŸ“ "Generated response: " + response

ğŸ“ "Testing code generation..."
ğŸ” code = generate_code(llm)
ğŸ“ "Generated code: \n" + code

ğŸ“ "LLM system test completed âœ“"

// Test 3: Reasoning System
ğŸ“ "\n=== Test 3: Reasoning System ==="
ğŸ§  reasoning = initialize_reasoning_system()

ğŸ“ "Testing chain of thought reasoning..."
ğŸ”  problem = "Calculate how many 2x2 tiles are needed to cover a floor that is 5x3 meters, if each tile is 20x20 cm."
ğŸ” steps = chain_of_thought(reasoning, problem)

ğŸ“ "Chain of thought steps:"
for (ğŸ”¢ i = 0; i < steps.length; i++) {
  ğŸ“ (i+1) + ". " + steps[i]
}

ğŸ“ "Testing planning system..."
ğŸ” plan = create_plan(reasoning, problem)
ğŸ“ "Generated plan:"
for (ğŸ”¢ i = 0; i < plan.length; i++) {
  ğŸ“ (i+1) + ". " + plan[i]
}

ğŸ“ "Testing plan execution..."
ğŸ” result = execute_plan(reasoning, plan)
ğŸ“ "Plan execution result: " + result

ğŸ“ "Testing self-correction..."
ğŸ”  code_with_errors = "ğŸ”  calculate_area(x, y) {\n  ğŸ“¤ x + y // This should be x * y\n}"
ğŸ” corrected_code = self_correct(reasoning, code_with_errors)
ğŸ“ "Original code: \n" + code_with_errors
ğŸ“ "Corrected code: \n" + corrected_code

ğŸ“ "Reasoning system test completed âœ“"

// Test 4: Tools System
ğŸ“ "\n=== Test 4: Tools System ==="
ğŸ§  tools = initialize_tools_system()

ğŸ“ "Testing web tools..."
ğŸ” search_results = web_search(tools, "Anarchy Inference language")
ğŸ“ "Web search results:"
for (ğŸ”¢ i = 0; i < search_results.length; i++) {
  ğŸ“ (i+1) + ". " + search_results[i].title + " - " + search_results[i].url
}

ğŸ“ "Testing file system tools..."
ğŸ” files = list_files(tools, "./")
ğŸ“ "Files in current directory:"
for (ğŸ”¢ i = 0; i < files.length; i++) {
  ğŸ“ "- " + files[i]
}

ğŸ“ "Testing file write and read..."
write_file(tools, "test_output.txt", "This is a test file created by anarchy-agent.")
ğŸ” content = read_file(tools, "test_output.txt")
ğŸ“ "File content: " + content

ğŸ“ "Testing shell tools..."
ğŸ” command_output = execute_command(tools, "echo 'Hello from anarchy-agent!'")
ğŸ“ "Command output: " + command_output

ğŸ“ "Tools system test completed âœ“"

// Test 5: Workflow Integration
ğŸ“ "\n=== Test 5: Workflow Integration ==="
ğŸ§  agent = initialize_agent()

ğŸ“ "Testing task processing..."
ğŸ”  task = "Find information about climate change, summarize it, and save the summary to a file."
ğŸ” task_result = process_task(agent, task)
ğŸ“ "Task processing result: " + task_result

ğŸ“ "Workflow integration test completed âœ“"

// Final report
ğŸ“ "\n=== Comprehensive Test Results ==="
ğŸ“ "All systems tested successfully!"
ğŸ“ "Memory System: âœ“"
ğŸ“ "LLM System: âœ“"
ğŸ“ "Reasoning System: âœ“"
ğŸ“ "Tools System: âœ“"
ğŸ“ "Workflow Integration: âœ“"
ğŸ“ "Test completed at: " + new Date().toString()
EOF

echo "Creating performance test file..."
cat > performance_test.a.i << 'EOF'
// performance_test.a.i - Performance test for anarchy-agent

ğŸ“ "=== anarchy-agent Performance Test ==="
ğŸ“ "Starting test at: " + new Date().toString()

// Import core modules
ğŸ”„ "./src/memory/enhanced/memory_integration.a.i"
ğŸ”„ "./src/llm/llm_integration.a.i"
ğŸ”„ "./src/reasoning/reasoning_integration.a.i"
ğŸ”„ "./src/tools/tools_integration.a.i"
ğŸ”„ "./src/integration/workflow_integration.a.i"

// Helper function to measure execution time
ğŸ”  time_execution(func, ...args) {
  ğŸ” start_time = new Date().getTime()
  ğŸ” result = func(...args)
  ğŸ” end_time = new Date().getTime()
  ğŸ” elapsed = end_time - start_time
  
  ğŸ“¤ {
    "result": result,
    "time_ms": elapsed
  }
}

// Test 1: Memory System Performance
ğŸ“ "\n=== Memory System Performance ==="
ğŸ§  memory = initialize_memory_system()

// Test memory storage performance
ğŸ“ "Testing memory storage performance..."
ğŸ” storage_times = ğŸ“¦ []
for (ğŸ”¢ i = 0; i < 100; i++) {
  ğŸ” timed = time_execution(store_memory, memory, "perf/item" + i, "Value " + i)
  storage_times.push(timed.time_ms)
}

ğŸ” avg_storage_time = storage_times.reduce((a, b) => a + b, 0) / storage_times.length
ğŸ“ "Average time to store a memory: " + avg_storage_time + "ms"

// Test memory retrieval performance
ğŸ“ "Testing memory retrieval performance..."
ğŸ” retrieval_times = ğŸ“¦ []
for (ğŸ”¢ i = 0; i < 100; i++) {
  ğŸ” timed = time_execution(retrieve_memory, memory, "perf/item" + i)
  retrieval_times.push(timed.time_ms)
}

ğŸ” avg_retrieval_time = retrieval_times.reduce((a, b) => a + b, 0) / retrieval_times.length
ğŸ“ "Average time to retrieve a memory: " + avg_retrieval_time + "ms"

// Test category search performance
ğŸ“ "Testing category search performance..."
ğŸ” search_timed = time_execution(search_by_category, memory, "perf")
ğŸ“ "Time to search category with 100 items: " + search_timed.time_ms + "ms"

// Test 2: LLM System Performance
ğŸ“ "\n=== LLM System Performance ==="
ğŸ§  llm = initialize_llm_system()

// Test context management performance
ğŸ“ "Testing context management performance..."
ğŸ” context_times = ğŸ“¦ []
for (ğŸ”¢ i = 0; i < 100; i++) {
  ğŸ” timed = time_execution(add_to_context, llm, "user", "Message " + i)
  context_times.push(timed.time_ms)
}

ğŸ” avg_context_time = context_times.reduce((a, b) => a + b, 0) / context_times.length
ğŸ“ "Average time to add to context: " + avg_context_time + "ms"

// Test response generation performance
ğŸ“ "Testing response generation performance..."
ğŸ” response_timed = time_execution(generate_response, llm)
ğŸ“ "Time to generate response: " + response_timed.time_ms + "ms"

// Test 3: Reasoning System Performance
ğŸ“ "\n=== Reasoning System Performance ==="
ğŸ§  reasoning = initialize_reasoning_system()

// Test chain of thought performance
ğŸ“ "Testing chain of thought performance..."
ğŸ”  problem = "Calculate how many 2x2 tiles are needed to cover a floor that is 5x3 meters, if each tile is 20x20 cm."
ğŸ” cot_timed = time_execution(chain_of_thought, reasoning, problem)
ğŸ“ "Time for chain of thought reasoning: " + cot_timed.time_ms + "ms"

// Test planning performance
ğŸ“ "Testing planning performance..."
ğŸ” plan_timed = time_execution(create_plan, reasoning, problem)
ğŸ“ "Time to create a plan: " + plan_timed.time_ms + "ms"

// Test 4: Tools System Performance
ğŸ“ "\n=== Tools System Performance ==="
ğŸ§  tools = initialize_tools_system()

// Test file operations performance
ğŸ“ "Testing file operations performance..."
ğŸ” write_timed = time_execution(write_file, tools, "perf_test.txt", "Performance test content")
ğŸ“ "Time to write a file: " + write_timed.time_ms + "ms"

ğŸ” read_timed = time_execution(read_file, tools, "perf_test.txt")
ğŸ“ "Time to read a file: " + read_timed.time_ms + "ms"

// Test 5: Workflow Integration Performance
ğŸ“ "\n=== Workflow Integration Performance ==="
ğŸ§  agent = initialize_agent()

// Test task processing performance
ğŸ“ "Testing task processing performance..."
ğŸ”  task = "Find information about climate change, summarize it, and save the summary to a file."
ğŸ” task_timed = time_execution(process_task, agent, task)
ğŸ“ "Time to process a task: " + task_timed.time_ms + "ms"

// Final report
ğŸ“ "\n=== Performance Test Results ==="
ğŸ“ "Memory System:"
ğŸ“ "- Storage: " + avg_storage_time + "ms per operation"
ğŸ“ "- Retrieval: " + avg_retrieval_time + "ms per operation"
ğŸ“ "- Category Search: " + search_timed.time_ms + "ms for 100 items"

ğŸ“ "LLM System:"
ğŸ“ "- Context Management: " + avg_context_time + "ms per operation"
ğŸ“ "- Response Generation: " + response_timed.time_ms + "ms"

ğŸ“ "Reasoning System:"
ğŸ“ "- Chain of Thought: " + cot_timed.time_ms + "ms"
ğŸ“ "- Planning: " + plan_timed.time_ms + "ms"

ğŸ“ "Tools System:"
ğŸ“ "- File Write: " + write_timed.time_ms + "ms"
ğŸ“ "- File Read: " + read_timed.time_ms + "ms"

ğŸ“ "Workflow Integration:"
ğŸ“ "- Task Processing: " + task_timed.time_ms + "ms"

ğŸ“ "Test completed at: " + new Date().toString()
EOF

echo "Creating stress test file..."
cat > stress_test.a.i << 'EOF'
// stress_test.a.i - Stress test for anarchy-agent

ğŸ“ "=== anarchy-agent Stress Test ==="
ğŸ“ "Starting test at: " + new Date().toString()

// Import core modules
ğŸ”„ "./src/memory/enhanced/memory_integration.a.i"
ğŸ”„ "./src/llm/llm_integration.a.i"
ğŸ”„ "./src/reasoning/reasoning_integration.a.i"
ğŸ”„ "./src/tools/tools_integration.a.i"
ğŸ”„ "./src/integration/workflow_integration.a.i"

// Test 1: Memory System Stress Test
ğŸ“ "\n=== Memory System Stress Test ==="
ğŸ§  memory = initialize_memory_system()

// Store a large number of memories
ğŸ“ "Storing 1000 memories..."
for (ğŸ”¢ i = 0; i < 1000; i++) {
  store_memory(memory, "stress/item" + i, "Value " + i)
}

// Verify storage
ğŸ“ "Verifying storage..."
ğŸ” errors = 0
for (ğŸ”¢ i = 0; i < 1000; i++) {
  ğŸ” value = retrieve_memory(memory, "stress/item" + i)
  if (value != "Value " + i) {
    errors++
  }
}

ğŸ“ "Storage verification complete with " + errors + " errors"

// Test category search with large dataset
ğŸ“ "Testing category search with 1000 items..."
ğŸ” results = search_by_category(memory, "stress")
ğŸ“ "Found " + results.length + " items in category"

// Test 2: LLM System Stress Test
ğŸ“ "\n=== LLM System Stress Test ==="
ğŸ§  llm = initialize_llm_system()

// Add a large context
ğŸ“ "Adding 1000 messages to context..."
for (ğŸ”¢ i = 0; i < 1000; i++) {
  add_to_context(llm, "user", "Message " + i)
}

ğŸ“ "Context now contains " + llm.context.user.length + " user messages"

// Test response generation with large context
ğŸ“ "Testing response generation with large context..."
ğŸ” response = generate_response(llm)
ğŸ“ "Response generated successfully"

// Test 3: Reasoning System Stress Test
ğŸ“ "\n=== Reasoning System Stress Test ==="
ğŸ§  reasoning = initialize_reasoning_system()

// Test with complex problem
ğŸ“ "Testing reasoning with complex problem..."
ğŸ”  complex_problem = "A train leaves station A at 2:00 PM traveling at 60 mph. Another train leaves station B, 200 miles away, at 3:00 PM traveling at 75 mph towards station A. At what time will the two trains meet? Additionally, if each train has 8 cars and each car can hold 80 passengers, how many total passengers can both trains carry? If tickets cost $25 per passenger, what is the maximum revenue possible from selling all tickets?"

ğŸ” steps = chain_of_thought(reasoning, complex_problem)
ğŸ“ "Generated " + steps.length + " reasoning steps"

ğŸ” plan = create_plan(reasoning, complex_problem)
ğŸ“ "Generated plan with " + plan.length + " steps"

// Test 4: Tools System Stress Test
ğŸ“ "\n=== Tools System Stress Test ==="
ğŸ§  tools = initialize_tools_system()

// Test with large file
ğŸ“ "Testing file operations with large content..."
ğŸ”  large_content = ""
for (ğŸ”¢ i = 0; i < 10000; i++) {
  large_content += "Line " + i + " of test content\n"
}

write_file(tools, "large_test.txt", large_content)
ğŸ” read_content = read_file(tools, "large_test.txt")
ğŸ“ "Successfully wrote and read file with " + large_content.length + " characters"

// Test 5: Workflow Integration Stress Test
ğŸ“ "\n=== Workflow Integration Stress Test ==="
ğŸ§  agent = initialize_agent()

// Test with multiple tasks
ğŸ“ "Processing 10 tasks in sequence..."
for (ğŸ”¢ i = 0; i < 10; i++) {
  ğŸ”  task = "Task " + i + ": Analyze data, generate report, and save results."
  ğŸ” result = process_task(agent, task)
  ğŸ“ "Task " + i + " result: " + result
}

// Final report
ğŸ“ "\n=== Stress Test Results ==="
ğŸ“ "All stress tests completed successfully!"
ğŸ“ "Memory System: Handled 1000 items with " + errors + " errors"
ğŸ“ "LLM System: Handled context with " + llm.context.user.length + " messages"
ğŸ“ "Reasoning System: Processed complex problem with " + steps.length + " steps"
ğŸ“ "Tools System: Handled file with " + large_content.length + " characters"
ğŸ“ "Workflow Integration: Processed 10 sequential tasks"
ğŸ“ "Test completed at: " + new Date().toString()
EOF

echo "Making test files executable..."
chmod +x comprehensive_test.a.i
chmod +x performance_test.a.i
chmod +x stress_test.a.i

echo ""
echo "=== Test Scripts Created! ==="
echo ""
echo "To run the comprehensive test:"
echo "  cd ~/anarchy-projects/anarchy-agent"
echo "  anarchy-inference comprehensive_test.a.i"
echo ""
echo "To run the performance test:"
echo "  anarchy-inference performance_test.a.i"
echo ""
echo "To run the stress test:"
echo "  anarchy-inference stress_test.a.i"
echo ""
echo "For more information, see the LOCAL_DEPLOYMENT_GUIDE.md file."
