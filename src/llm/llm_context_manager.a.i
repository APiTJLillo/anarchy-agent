// llm_context_manager.a.i - Advanced context management for LLM integration
// Implements hierarchical context, compression, and relevance filtering

// Define string dictionary entries for context management
ðŸ“("context_init", "Initializing context manager...");
ðŸ“("context_add", "Adding to context: {} (type: {})");
ðŸ“("context_compress", "Compressing context: {} tokens -> {} tokens");
ðŸ“("context_retrieve", "Retrieving relevant context for: {}");
ðŸ“("context_error", "Context manager error: {}");
ðŸ“("context_clear", "Clearing context");

// Context Manager Module Definition
Î»LLMContextManager {
    // Initialize context manager
    Æ’initialize(Î±options) {
        âŒ½(:context_init);
        
        // Set default options
        Î¹this.options = options || {};
        Î¹this.options.max_context_length = this.options.max_context_length || 8192;
        Î¹this.options.compression_threshold = this.options.compression_threshold || 6144;
        Î¹this.options.max_conversation_turns = this.options.max_conversation_turns || 20;
        Î¹this.options.relevance_threshold = this.options.relevance_threshold || 0.6;
        
        // Initialize context storage
        Î¹this.conversation_history = [];
        Î¹this.code_snippets = [];
        Î¹this.task_history = [];
        Î¹this.system_messages = [];
        Î¹this.user_preferences = {};
        
        // Initialize context metadata
        Î¹this.context_token_count = 0;
        Î¹this.last_compression_time = Date.now();
        
        âŸ¼(âŠ¤);
    }
    
    // Add a conversation turn to context
    Æ’add_conversation(Ïƒrole, Ïƒcontent, Î±metadata) {
        âŒ½(:context_add, content.substring(0, 30) + "...", "conversation");
        
        // Create conversation entry
        Î¹entry = {
            role: role,
            content: content,
            timestamp: Date.now(),
            metadata: metadata || {},
            token_estimate: this._estimate_tokens(content)
        };
        
        // Add to conversation history
        ï¼‹(this.conversation_history, entry);
        
        // Update token count
        this.context_token_count += entry.token_estimate;
        
        // Check if compression is needed
        if (this.context_token_count > this.options.compression_threshold) {
            this._compress_context();
        }
        
        // Trim conversation history if it exceeds maximum turns
        if (this.conversation_history.length > this.options.max_conversation_turns) {
            Î¹removed = this.conversation_history.shift();
            this.context_token_count -= removed.token_estimate;
        }
        
        âŸ¼(âŠ¤);
    }
    
    // Add a code snippet to context
    Æ’add_code_snippet(Ïƒcode, Ïƒdescription, Î±tags) {
        âŒ½(:context_add, description, "code_snippet");
        
        // Create code snippet entry
        Î¹entry = {
            code: code,
            description: description,
            tags: tags || [],
            timestamp: Date.now(),
            token_estimate: this._estimate_tokens(code) + this._estimate_tokens(description)
        };
        
        // Add to code snippets
        ï¼‹(this.code_snippets, entry);
        
        // Update token count
        this.context_token_count += entry.token_estimate;
        
        // Check if compression is needed
        if (this.context_token_count > this.options.compression_threshold) {
            this._compress_context();
        }
        
        âŸ¼(âŠ¤);
    }
    
    // Add a task to history
    Æ’add_task(Ïƒtask_description, Î±result, Î±metadata) {
        âŒ½(:context_add, task_description.substring(0, 30) + "...", "task");
        
        // Create task entry
        Î¹entry = {
            description: task_description,
            result: result || null,
            status: result ? "completed" : "pending",
            timestamp: Date.now(),
            metadata: metadata || {},
            token_estimate: this._estimate_tokens(task_description) + 
                           (result ? this._estimate_tokens(JSON.stringify(result)) : 0)
        };
        
        // Add to task history
        ï¼‹(this.task_history, entry);
        
        // Update token count
        this.context_token_count += entry.token_estimate;
        
        // Check if compression is needed
        if (this.context_token_count > this.options.compression_threshold) {
            this._compress_context();
        }
        
        âŸ¼(âŠ¤);
    }
    
    // Add a system message to context
    Æ’add_system_message(Ïƒmessage, Î¹importance) {
        âŒ½(:context_add, message.substring(0, 30) + "...", "system");
        
        // Create system message entry
        Î¹entry = {
            message: message,
            importance: importance || 1, // 1-5 scale
            timestamp: Date.now(),
            token_estimate: this._estimate_tokens(message)
        };
        
        // Add to system messages
        ï¼‹(this.system_messages, entry);
        
        // Update token count
        this.context_token_count += entry.token_estimate;
        
        âŸ¼(âŠ¤);
    }
    
    // Set user preference
    Æ’set_user_preference(Ïƒkey, Î±value) {
        this.user_preferences[key] = value;
        âŸ¼(âŠ¤);
    }
    
    // Get user preference
    Æ’get_user_preference(Ïƒkey) {
        âŸ¼(this.user_preferences[key]);
    }
    
    // Get relevant context for a query
    Æ’get_relevant_context(Ïƒquery, Î±options) {
        âŒ½(:context_retrieve, query);
        
        // Set retrieval options
        Î¹retrieval_options = options || {};
        Î¹max_tokens = retrieval_options.max_tokens || this.options.max_context_length;
        Î¹include_conversation = retrieval_options.include_conversation !== undefined ? 
                               retrieval_options.include_conversation : âŠ¤;
        Î¹include_code = retrieval_options.include_code !== undefined ? 
                       retrieval_options.include_code : âŠ¤;
        Î¹include_tasks = retrieval_options.include_tasks !== undefined ? 
                        retrieval_options.include_tasks : âŠ¤;
        Î¹include_system = retrieval_options.include_system !== undefined ? 
                         retrieval_options.include_system : âŠ¤;
        
        // Initialize context parts
        Î¹relevant_context = {
            conversation: [],
            code_snippets: [],
            tasks: [],
            system_messages: [],
            user_preferences: this.user_preferences
        };
        
        // Get relevant conversation turns
        if (include_conversation) {
            relevant_context.conversation = this._get_relevant_conversation(query, max_tokens * 0.4);
        }
        
        // Get relevant code snippets
        if (include_code) {
            relevant_context.code_snippets = this._get_relevant_code_snippets(query, max_tokens * 0.3);
        }
        
        // Get relevant tasks
        if (include_tasks) {
            relevant_context.tasks = this._get_relevant_tasks(query, max_tokens * 0.2);
        }
        
        // Get relevant system messages
        if (include_system) {
            relevant_context.system_messages = this._get_relevant_system_messages(max_tokens * 0.1);
        }
        
        âŸ¼(relevant_context);
    }
    
    // Format context for LLM prompt
    Æ’format_context_for_prompt(Î±relevant_context, Ïƒformat_type) {
        Î¹format = format_type || "default";
        Î¹formatted = "";
        
        if (format === "default" || format === "conversation") {
            // Format conversation history
            if (relevant_context.conversation && relevant_context.conversation.length > 0) {
                formatted += "## Conversation History\n\n";
                âˆ€(relevant_context.conversation, Î»turn {
                    formatted += `${turn.role}: ${turn.content}\n\n`;
                });
            }
            
            // Format code snippets
            if (relevant_context.code_snippets && relevant_context.code_snippets.length > 0) {
                formatted += "## Relevant Code Snippets\n\n";
                âˆ€(relevant_context.code_snippets, Î»snippet {
                    formatted += `### ${snippet.description}\n\`\`\`\n${snippet.code}\n\`\`\`\n\n`;
                });
            }
            
            // Format tasks
            if (relevant_context.tasks && relevant_context.tasks.length > 0) {
                formatted += "## Recent Tasks\n\n";
                âˆ€(relevant_context.tasks, Î»task {
                    formatted += `- ${task.description} (${task.status})\n`;
                });
                formatted += "\n";
            }
            
            // Format system messages
            if (relevant_context.system_messages && relevant_context.system_messages.length > 0) {
                formatted += "## System Information\n\n";
                âˆ€(relevant_context.system_messages, Î»msg {
                    formatted += `- ${msg.message}\n`;
                });
                formatted += "\n";
            }
            
            // Format user preferences
            if (relevant_context.user_preferences && Object.keys(relevant_context.user_preferences).length > 0) {
                formatted += "## User Preferences\n\n";
                âˆ€(Object.keys(relevant_context.user_preferences), Î»key {
                    formatted += `- ${key}: ${relevant_context.user_preferences[key]}\n`;
                });
                formatted += "\n";
            }
        } else if (format === "code_generation") {
            // Format specifically for code generation
            
            // Format code snippets first (most important for code generation)
            if (relevant_context.code_snippets && relevant_context.code_snippets.length > 0) {
                formatted += "## Relevant Code Examples\n\n";
                âˆ€(relevant_context.code_snippets, Î»snippet {
                    formatted += `### ${snippet.description}\n\`\`\`\n${snippet.code}\n\`\`\`\n\n`;
                });
            }
            
            // Format relevant conversation turns that mention code
            if (relevant_context.conversation && relevant_context.conversation.length > 0) {
                Î¹code_related_turns = relevant_context.conversation.filter(turn => 
                    turn.content.includes("code") || 
                    turn.content.includes("function") || 
                    turn.content.includes("Æ’") ||
                    turn.content.includes("Î»")
                );
                
                if (code_related_turns.length > 0) {
                    formatted += "## Relevant Conversation\n\n";
                    âˆ€(code_related_turns, Î»turn {
                        formatted += `${turn.role}: ${turn.content}\n\n`;
                    });
                }
            }
            
            // Format user preferences related to code
            if (relevant_context.user_preferences) {
                Î¹code_preferences = {};
                if (relevant_context.user_preferences.code_style) code_preferences.code_style = relevant_context.user_preferences.code_style;
                if (relevant_context.user_preferences.preferred_emoji_operators) code_preferences.preferred_emoji_operators = relevant_context.user_preferences.preferred_emoji_operators;
                
                if (Object.keys(code_preferences).length > 0) {
                    formatted += "## Code Preferences\n\n";
                    âˆ€(Object.keys(code_preferences), Î»key {
                        formatted += `- ${key}: ${code_preferences[key]}\n`;
                    });
                    formatted += "\n";
                }
            }
        }
        
        âŸ¼(formatted);
    }
    
    // Clear all context
    Æ’clear_context() {
        âŒ½(:context_clear);
        
        this.conversation_history = [];
        this.code_snippets = [];
        this.task_history = [];
        this.system_messages = [];
        this.context_token_count = 0;
        
        // Keep user preferences
        
        âŸ¼(âŠ¤);
    }
    
    // Get total token count
    Æ’get_token_count() {
        âŸ¼(this.context_token_count);
    }
    
    // Get context statistics
    Æ’get_context_stats() {
        âŸ¼({
            total_tokens: this.context_token_count,
            conversation_turns: this.conversation_history.length,
            code_snippets: this.code_snippets.length,
            tasks: this.task_history.length,
            system_messages: this.system_messages.length,
            user_preferences: Object.keys(this.user_preferences).length,
            last_compression_time: this.last_compression_time
        });
    }
    
    // Private: Compress context to reduce token count
    Æ’_compress_context() {
        Î¹original_tokens = this.context_token_count;
        
        // Compress by summarizing older conversation turns
        if (this.conversation_history.length > 5) {
            Î¹to_summarize = this.conversation_history.slice(0, this.conversation_history.length - 5);
            Î¹to_keep = this.conversation_history.slice(this.conversation_history.length - 5);
            
            // Create summary of older turns
            Î¹summary_content = "Summary of previous conversation: ";
            âˆ€(to_summarize, Î»turn {
                summary_content += `${turn.role} discussed ${turn.content.substring(0, 30)}... `;
            });
            
            // Create summary entry
            Î¹summary_entry = {
                role: "system",
                content: summary_content,
                timestamp: Date.now(),
                metadata: { is_summary: âŠ¤ },
                token_estimate: this._estimate_tokens(summary_content)
            };
            
            // Calculate token savings
            Î¹old_tokens = 0;
            âˆ€(to_summarize, Î»turn {
                old_tokens += turn.token_estimate;
            });
            
            // Update context
            this.conversation_history = [summary_entry, ...to_keep];
            this.context_token_count = this.context_token_count - old_tokens + summary_entry.token_estimate;
        }
        
        // Remove oldest code snippets if still over threshold
        if (this.context_token_count > this.options.compression_threshold && this.code_snippets.length > 3) {
            // Sort by timestamp (oldest first)
            this.code_snippets.sort((a, b) => a.timestamp - b.timestamp);
            
            // Remove oldest snippets until under threshold or only 3 remain
            while (this.context_token_count > this.options.compression_threshold && this.code_snippets.length > 3) {
                Î¹removed = this.code_snippets.shift();
                this.context_token_count -= removed.token_estimate;
            }
        }
        
        // Remove oldest tasks if still over threshold
        if (this.context_token_count > this.options.compression_threshold && this.task_history.length > 5) {
            // Sort by timestamp (oldest first)
            this.task_history.sort((a, b) => a.timestamp - b.timestamp);
            
            // Remove oldest tasks until under threshold or only 5 remain
            while (this.context_token_count > this.options.compression_threshold && this.task_history.length > 5) {
                Î¹removed = this.task_history.shift();
                this.context_token_count -= removed.token_estimate;
            }
        }
        
        // Remove low importance system messages if still over threshold
        if (this.context_token_count > this.options.compression_threshold && this.system_messages.length > 0) {
            // Sort by importance (lowest first)
            this.system_messages.sort((a, b) => a.importance - b.importance);
            
            // Remove lowest importance messages until under threshold or none remain
            while (this.context_token_count > this.options.compression_threshold && this.system_messages.length > 0) {
                Î¹removed = this.system_messages.shift();
                this.context_token_count -= removed.token_estimate;
            }
        }
        
        // Update compression time
        this.last_compression_time = Date.now();
        
        âŒ½(:context_compress, original_tokens, this.context_token_count);
    }
    
    // Private: Get relevant conversation turns for a query
    Æ’_get_relevant_conversation(Ïƒquery, Î¹max_tokens) {
        // Start with most recent turns
        Î¹recent_turns = this.conversation_history.slice(-3);
        
        // Calculate tokens used by recent turns
        Î¹tokens_used = 0;
        âˆ€(recent_turns, Î»turn {
            tokens_used += turn.token_estimate;
        });
        
        // If we have room for more, add relevant older turns
        if (tokens_used < max_tokens && this.conversation_history.length > 3) {
            Î¹older_turns = this.conversation_history.slice(0, -3);
            
            // Calculate relevance scores for older turns
            Î¹scored_turns = older_turns.map(turn => {
                âŸ¼({
                    turn: turn,
                    score: this._calculate_relevance(query, turn.content)
                });
            });
            
            // Sort by relevance score (highest first)
            scored_turns.sort((a, b) => b.score - a.score);
            
            // Add relevant turns until we hit the token limit
            âˆ€(scored_turns, Î»scored_turn {
                if (tokens_used + scored_turn.turn.token_estimate <= max_tokens && 
                    scored_turn.score >= this.options.relevance_threshold) {
                    ï¼‹(recent_turns, scored_turn.turn);
                    tokens_used += scored_turn.turn.token_estimate;
                }
            });
            
            // Sort by timestamp to maintain chronological order
            recent_turns.sort((a, b) => a.timestamp - b.timestamp);
        }
        
        âŸ¼(recent_turns);
    }
    
    // Private: Get relevant code snippets for a query
    Æ’_get_relevant_code_snippets(Ïƒquery, Î¹max_tokens) {
        if (this.code_snippets.length === 0) {
            âŸ¼([]);
        }
        
        // Calculate relevance scores for code snippets
        Î¹scored_snippets = this.code_snippets.map(snippet => {
            Î¹combined_text = snippet.description + " " + snippet.code;
            âŸ¼({
                snippet: snippet,
                score: this._calculate_relevance(query, combined_text)
            });
        });
        
        // Sort by relevance score (highest first)
        scored_snippets.sort((a, b) => b.score - a.score);
        
        // Select relevant snippets until we hit the token limit
        Î¹selected_snippets = [];
        Î¹tokens_used = 0;
        
        âˆ€(scored_snippets, Î»scored_snippet {
            if (tokens_used + scored_snippet.snippet.token_estimate <= max_tokens && 
                scored_snippet.score >= this.options.relevance_threshold) {
                ï¼‹(selected_snippets, scored_snippet.snippet);
                tokens_used += scored_snippet.snippet.token_estimate;
            }
        });
        
        âŸ¼(selected_snippets);
    }
    
    // Private: Get relevant tasks for a query
    Æ’_get_relevant_tasks(Ïƒquery, Î¹max_tokens) {
        if (this.task_history.length === 0) {
            âŸ¼([]);
        }
        
        // Always include the most recent task
        Î¹recent_task = this.task_history[this.task_history.length - 1];
        Î¹selected_tasks = [recent_task];
        Î¹tokens_used = recent_task.token_estimate;
        
        // If we have room for more, add relevant older tasks
        if (tokens_used < max_tokens && this.task_history.length > 1) {
            Î¹older_tasks = this.task_history.slice(0, -1);
            
            // Calculate relevance scores for older tasks
            Î¹scored_tasks = older_tasks.map(task => {
                Î¹combined_text = task.description + " " + (task.result ? JSON.stringify(task.result) : "");
                âŸ¼({
                    task: task,
                    score: this._calculate_relevance(query, combined_text)
                });
            });
            
            // Sort by relevance score (highest first)
            scored_tasks.sort((a, b) => b.score - a.score);
            
            // Add relevant tasks until we hit the token limit
            âˆ€(scored_tasks, Î»scored_task {
                if (tokens_used + scored_task.task.token_estimate <= max_tokens && 
                    scored_task.score >= this.options.relevance_threshold) {
                    ï¼‹(selected_tasks, scored_task.task);
                    tokens_used += scored_task.task.token_estimate;
                }
            });
        }
        
        âŸ¼(selected_tasks);
    }
    
    // Private: Get relevant system messages
    Æ’_get_relevant_system_messages(Î¹max_tokens) {
        if (this.system_messages.length === 0) {
            âŸ¼([]);
        }
        
        // Sort by importance (highest first)
        Î¹sorted_messages = [...this.system_messages].sort((a, b) => b.importance - a.importance);
        
        // Select messages until we hit the token limit
        Î¹selected_messages = [];
        Î¹tokens_used = 0;
        
        âˆ€(sorted_messages, Î»message {
            if (tokens_used + message.token_estimate <= max_tokens) {
                ï¼‹(selected_messages, message);
                tokens_used += message.token_estimate;
            }
        });
        
        âŸ¼(selected_messages);
    }
    
    // Private: Calculate relevance score between query and text
    Æ’_calculate_relevance(Ïƒquery, Ïƒtext) {
        // In a real implementation, this would use embeddings or more sophisticated matching
        // For this example, we'll use a simple keyword matching approach
        
        // Normalize text
        Î¹normalized_query = query.toLowerCase();
        Î¹normalized_text = text.toLowerCase();
        
        // Split into words
        Î¹query_words = normalized_query.split(/\s+/);
        
        // Count matching words
        Î¹matches = 0;
        âˆ€(query_words, Î»word {
            if (normalized_text.includes(word)) {
                matches++;
            }
        });
        
        // Calculate score (0-1)
        Î¹score = query_words.length > 0 ? matches / query_words.length : 0;
        
        âŸ¼(score);
    }
    
    // Private: Estimate token count for a string
    Æ’_estimate_tokens(Ïƒtext) {
        // Simple estimation: ~4 characters per token
        âŸ¼(Math.ceil(text.length / 4));
    }
}

// Export the LLMContextManager module
âŸ¼(LLMContextManager);
