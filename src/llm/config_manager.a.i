// config_manager.a.i
// Configuration management for LLM providers

ğŸ”  create_config_manager() {
  // Create a new configuration manager
  ğŸ“¤ {
    // Load configuration from a file
    load_config: ğŸ”(path) {
      // Read the configuration file
      ğŸ§  config_text = ""
      try {
        config_text = ğŸ“–(path)
      } catch (error) {
        ğŸ“¤ { error: "Failed to read configuration file: " + path }
      }
      
      // Parse the configuration
      try {
        ğŸ§  config = JSON.parse(config_text)
        ğŸ“¤ config
      } catch (error) {
        ğŸ“¤ { error: "Failed to parse configuration file: Invalid JSON" }
      }
    },
    
    // Save configuration to a file
    save_config: ğŸ”(config, path) {
      try {
        // Convert config to JSON string with pretty formatting
        ğŸ§  config_text = JSON.stringify(config, null, 2)
        
        // Write to file
        âœ(path, config_text)
        ğŸ“¤ true
      } catch (error) {
        ğŸ“¤ false
      }
    },
    
    // Get API key for a specific provider
    get_api_key: ğŸ”(config, provider_name) {
      if (!config || !config.providers || !config.providers[provider_name]) {
        ğŸ“¤ null
      }
      
      // Check for API key in provider config
      ğŸ§  provider_config = config.providers[provider_name]
      if (provider_config.api_key) {
        ğŸ“¤ provider_config.api_key
      }
      
      // Check for environment variable
      ğŸ§  env_var_name = provider_name.toUpperCase() + "_API_KEY"
      ğŸ§  env_api_key = get_environment_variable(env_var_name)
      if (env_api_key) {
        ğŸ“¤ env_api_key
      }
      
      ğŸ“¤ null
    },
    
    // Get configuration for a specific provider
    get_provider_config: ğŸ”(config, provider_name) {
      if (!config || !config.providers || !config.providers[provider_name]) {
        ğŸ“¤ {}
      }
      
      ğŸ“¤ config.providers[provider_name]
    },
    
    // Get the default provider name
    get_default_provider: ğŸ”(config) {
      if (!config || !config.default_provider) {
        ğŸ“¤ "openai" // Default to OpenAI if not specified
      }
      
      ğŸ“¤ config.default_provider
    },
    
    // Get the fallback chain (ordered list of providers to try)
    get_fallback_chain: ğŸ”(config) {
      if (!config || !config.fallback_chain || !Array.isArray(config.fallback_chain)) {
        ğŸ“¤ ["openai", "local"] // Default fallback chain
      }
      
      ğŸ“¤ config.fallback_chain
    },
    
    // Create a default configuration
    create_default_config: ğŸ”() {
      ğŸ“¤ {
        default_provider: "openai",
        fallback_chain: ["openai", "local", "claude"],
        providers: {
          openai: {
            api_key: "",
            model: "gpt-3.5-turbo",
            temperature: 0.7,
            max_tokens: 1000
          },
          azure_openai: {
            api_key: "",
            endpoint: "",
            deployment_name: "",
            api_version: "2023-05-15"
          },
          claude: {
            api_key: "",
            model: "claude-3-sonnet-20240229",
            temperature: 0.7
          },
          local: {
            endpoint: "http://localhost:11434",
            model: "llama3",
            temperature: 0.7
          }
        }
      }
    }
  }
}

// Helper function to get environment variable
// This is a placeholder since Anarchy Inference doesn't have direct env var access
ğŸ”  get_environment_variable(name) {
  // In a real implementation, this would access environment variables
  // For now, we'll use a file-based approach
  ğŸ§  env_file = "/tmp/anarchy_env_vars.json"
  
  try {
    ğŸ§  env_text = ğŸ“–(env_file)
    ğŸ§  env_vars = JSON.parse(env_text)
    if (env_vars[name]) {
      ğŸ“¤ env_vars[name]
    }
  } catch (error) {
    // File doesn't exist or isn't valid JSON
  }
  
  ğŸ“¤ null
}

// Export the config manager creator function
ğŸ“¤ {
  create_config_manager: create_config_manager
}
